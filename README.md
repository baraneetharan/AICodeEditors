# AI Awareness Session
# Day 1 - AI Code Editors Introduction

## Overview

This session introduces participants to the transformative role of AI-powered code editors in modern software development. We will explore how these tools integrate into the Software Development Life Cycle (SDLC), their types, benefits, challenges, and practical applications. 

The session is designed to provide both theoretical insights and actionable knowledge for developers, project managers, and organizations looking to leverage AI-driven tools to enhance productivity, collaboration, and code quality.

---

## 1. Understanding the Software Development Life Cycle (SDLC)

The Software Development Life Cycle (SDLC) is a structured process for planning, creating, testing, deploying, and maintaining software applications. It consists of several phases, each of which can benefit from AI-driven tools, particularly AI code editors. The primary SDLC phases include:

- **Requirement Analysis**: Gathering and analyzing project requirements.
- **System Design**: Creating architectural and technical designs.
- **Implementation (Coding)**: Writing and testing code.
- **Testing**: Verifying and validating software functionality.
- **Deployment**: Releasing the software to production.
- **Maintenance**: Ongoing support and updates.

AI code editors streamline these phases by automating repetitive tasks, providing intelligent suggestions, and enhancing collaboration.

![image.png](attachment:1c4caf42-3696-4ab5-8923-980b1e701036:image.png)

---

## 2. Software Development Tools: An Ecosystem Overview

To understand the role of AI code editors, it’s essential to contextualize them within the broader ecosystem of software development tools. These tools collectively support the SDLC and enable teams to build robust, scalable applications.

### 2.1 Integrated Development Environments (IDEs)

- **Definition**: IDEs are comprehensive software suites that provide tools for coding, debugging, testing, and deployment within a single interface.
- **Examples**: IntelliJ IDEA, Visual Studio, Eclipse.
- **AI Integration**: Modern IDEs increasingly incorporate AI features, such as code autocompletion, error detection, and refactoring suggestions.

### 2.2 Code Editors

- **Definition**: Lightweight tools focused on writing and editing code, often with customizable plugins.
- **Examples**: Visual Studio Code (VS Code), Sublime Text, Atom.
- **AI Integration**: AI-powered extensions like GitHub Copilot enhance code editors with real-time code suggestions and automation.

### 2.3 Command Line Interfaces (CLIs)

- **Definition**: Text-based interfaces for executing commands, often used for scripting and automation.
- **Examples**: Bash, PowerShell, Zsh.
- **AI Integration**: Emerging AI tools like Warp provide intelligent CLI suggestions and error correction.

### 2.4 Version Control and Collaboration

- **Definition**: Systems to track code changes and enable team collaboration.
- **Examples**: Git, GitHub, GitLab, Bitbucket.
- **AI Integration**: AI-driven tools analyze commit histories, suggest merge conflict resolutions, and predict potential bugs.

### 2.5 Containerization and Orchestration

- **Definition**: Technologies to package applications and manage their deployment across environments.
- **Examples**: Docker, Kubernetes.
- **AI Integration**: AI optimizes container resource allocation and predicts scaling needs.

### 2.6 Continuous Integration/Continuous Deployment (CI/CD)

- **Definition**: Practices to automate code integration, testing, and deployment.
- **Examples**: Jenkins, GitHub Actions, CircleCI.
- **AI Integration**: AI enhances CI/CD pipelines by predicting test failures and optimizing build processes.

### 2.7 API Development and Testing

- **Definition**: Tools for designing, developing, and testing APIs.
- **Examples**: Postman, Swagger, Insomnia.
- **AI Integration**: AI-driven tools validate API schemas and generate test cases.

### 2.8 Project Management and Collaboration

- **Definition**: Platforms to manage tasks, timelines, and team communication.
- **Examples**: Jira, Trello, Asana.
- **AI Integration**: AI predicts project risks, estimates task completion times, and automates status updates.

### 2.9 Specialized Tools

- **Examples**: Linters (ESLint), formatters (Prettier), and static analysis tools (SonarQube).
- **AI Integration**: AI enhances these tools with intelligent code quality assessments and automated fixes.

---

## 3. AI Code Editors: Definition and Importance

### 3.1 Definition

AI code editors are software tools that leverage artificial intelligence (machine learning, natural language processing, and predictive analytics) **to assist developers in writing, debugging, and optimizing code**. Unlike traditional code editors, AI-powered editors **provide context-aware suggestions, automate repetitive tasks, and learn from user behavior to improve productivity**.

### 3.2 Importance

- **Increased Productivity**: AI automates boilerplate code generation, reducing manual effort.
- **Improved Code Quality**: AI detects errors, suggests optimizations, and enforces coding standards.
- **Enhanced Collaboration**: AI-driven insights facilitate better code reviews and team coordination.
- **Accessibility**: AI lowers the learning curve for beginners by providing real-time guidance.
- **Scalability**: AI tools adapt to complex projects, supporting diverse programming languages and frameworks.

![Screenshot 2025-05-22 172101.png](attachment:ad5cc184-7812-4615-9e6f-9ca2dfafa082:Screenshot_2025-05-22_172101.png)

---

## 4. Types of AI Code Editors and When to Use Them

AI code editors vary in functionality, integration, and use cases. Below are the primary types and their applications:

### 4.1 Standalone AI Code Editors

- **Description**: Dedicated tools designed specifically with AI capabilities.
- **Examples**: Tabnine, Replit with Ghostwriter.
- **Use Cases**: Ideal for rapid prototyping, solo developers, and small projects requiring quick setup.

### 4.2 AI-Powered Extensions for Existing Editors

- **Description**: Plugins that integrate AI into popular code editors like VS Code or IntelliJ IDEA.
- **Examples**: GitHub Copilot, IntelliCode, Codeium.
- **Use Cases**: Suitable for teams using established editors, seeking AI enhancements without changing workflows.

### 4.3 Cloud-Based AI Coding Platforms

- **Description**: Web-based environments with built-in AI features.
- **Examples**: GitHub Codespaces, Replit, AWS Cloud9 with AI integrations.
- **Use Cases**: Best for collaborative projects, remote development, and environments requiring scalability.

### 4.4 Specialized AI Tools for Specific Languages/Frameworks

- **Description**: AI tools tailored for specific programming languages or frameworks.
- **Examples**: Kite (Python-focused), DeepCode (security-focused).
- **Use Cases**: Optimal for niche projects requiring language-specific optimizations or security checks.

### 4.5 When to Use Each Type

- **Standalone Editors**: Use for quick, lightweight projects or when experimenting with AI-driven coding.
- **AI Extensions**: Use in established workflows to enhance existing tools without disruption.
- **Cloud-Based Platforms**: Use for distributed teams, large-scale projects, or when hardware resources are limited.
- **Specialized Tools**: Use for projects requiring deep language-specific or security-focused AI support.

![image.png](attachment:2109124f-9703-4bbc-a2de-8618fab1138a:image.png)

---

## 5. How AI code editors work

- **Code Analysis and Understanding** - AI models analyze your codebase by parsing syntax, understanding structure, and building context about functions, variables, and dependencies across files
- **Real-time Code Completion** - As you type, the AI predicts what you're likely to write next based on context, coding patterns, and common programming practices, offering suggestions for variables, functions, and entire code blocks
- **Natural Language Processing** - AI interprets comments and docstrings to understand intent, and can generate code from natural language descriptions or explain existing code in plain English
- **Pattern Recognition** - The models are trained on millions of code repositories to recognize common coding patterns, best practices, and idiomatic ways of writing code in different programming languages
- **Context-Aware Suggestions** - AI considers the current file, imported libraries, variable scope, and project structure to provide relevant suggestions rather than generic completions
- **Error Detection and Fixing** - AI can identify potential bugs, syntax errors, security vulnerabilities, and suggest fixes or improvements in real-time
- **Code Generation** - From simple function stubs to complex algorithms, AI can generate entire code segments based on specifications, comments, or partial implementations
- **Multi-language Support** - Modern AI code editors support dozens of programming languages by leveraging transformer models trained on diverse codebases
- **Integration with Development Workflow** - AI assistants integrate with IDEs, version control systems, and debugging tools to provide seamless coding assistance throughout the development process
- **Continuous Learning** - Some systems adapt to your coding style and project-specific patterns to provide increasingly personalized suggestions over time
- **LLM Request-Response Cycle** - The editor sends your code context, cursor position, and relevant project information as input to large language models via API calls, which then return generated suggestions, completions, or explanations that get displayed in your editor interface.

## 6. Key limitations in LLMs

- **License and Usage Restrictions** - Many LLMs have specific licensing terms that limit commercial use, redistribution, or modification, with some requiring attribution or restricting certain applications
- **Token Size Limitations** - LLMs have maximum input/output token limits (typically 4K-200K tokens) which restricts the amount of text they can process in a single request, affecting long document analysis or large codebase understanding
- **Context Window Constraints** - Limited context length means LLMs can't maintain awareness of very long conversations or large amounts of background information, leading to inconsistent responses in extended interactions
- **Rate Limiting** - API providers impose request limits per minute/hour/day to manage server load and costs, which can bottleneck applications requiring frequent LLM calls
- **Model Type Variations** - Different LLM architectures (GPT, Claude, LLaMA, etc.) have varying capabilities, specializations, and performance characteristics that may not suit all use cases
- **Training Data Cutoff** - LLMs have knowledge cutoff dates beyond which they lack information about recent events, technologies, or developments
- **Computational Resource Requirements** - Running LLMs locally requires significant GPU memory and processing power, making them inaccessible for many developers and organizations
- **Hallucination and Accuracy Issues** - LLMs can generate plausible-sounding but incorrect information, especially for specialized domains or factual queries
- **Cost Constraints** - API usage costs can become substantial for high-volume applications, particularly with larger models or complex prompts
- **Latency and Response Time** - Network requests to LLM APIs introduce delays that can impact user experience in real-time applications
- **Language and Domain Limitations** - Performance varies significantly across different programming languages, natural languages, and specialized domains based on training data representation
- **Inconsistent Output Format** - LLMs may not always follow specified output formats or structures consistently, requiring additional parsing and validation logic.

## **7. Types of LLMs** based on different categorization schemes:

**By Architecture:**

- **Transformer-based models** like GPT, BERT, and T5 use attention mechanisms and are currently dominant
- **Recurrent models** like LSTM-based language models process text sequentially
- **Convolutional models** that use CNN architectures for language tasks
- **Hybrid architectures** combining multiple approaches

**By Training Approach:**

- **Autoregressive models** (GPT family) predict the next token given previous tokens
- **Masked language models** (BERT family) predict missing tokens in a sequence
- **Encoder-decoder models** (T5, BART) designed for sequence-to-sequence tasks
- **Instruction-tuned models** (ChatGPT, Claude) fine-tuned to follow human instructions
- **RLHF models** trained with Reinforcement Learning from Human Feedback

**By Capability and Specialization:**

- **General-purpose conversational models** (ChatGPT, Claude, Bard)
- **Code-specialized models** (Codex, CodeT5, StarCoder)
- **Domain-specific models** (BioBERT for medicine, FinBERT for finance)
- **Multimodal models** (GPT-4V, Claude-3) that handle text, images, and other media
- **Reasoning models** (o1, o1-mini) for complex problem-solving
- **Function-calling models** designed to interact with APIs and tools

**By Size and Deployment:**

- **Large models** (100B+ parameters like GPT-4, PaLM-2)
- **Medium models** (7B-70B parameters like Llama-2, Claude-3 Haiku)
- **Small/edge models** (under 7B parameters for mobile/local deployment)
- **Mixture of Experts (MoE)** models that activate only parts of their parameters

**By Training Data and Alignment:**

- **Base models** trained only on raw text prediction
- **Chat-optimized models** fine-tuned for conversation
- **Safety-aligned models** with additional training for harmful content prevention
- **Factual accuracy models** optimized for truthfulness over creativity

Each type serves different use cases, from creative writing and general conversation to specialized technical tasks and complex reasoning challenges.

## 8. Checklist to do before using AI Code Editors

## Pre-Setup Verification

**Code Repository Management**

- Pull the latest code from your version control system (Git, SVN, etc.) to ensure you're working with the most current codebase
- Verify you're on the correct branch for your development work
- Check for any merge conflicts or pending changes that need to be resolved
- Ensure your local repository is clean with no uncommitted changes that could interfere with AI suggestions

**Development Environment Configuration**

- Verify Java installation and JAVA_HOME environment variable settings
- Confirm Maven/Gradle paths are correctly configured in system PATH
- Check Node.js, Python, or other runtime versions match project requirements
- Validate IDE-specific configurations like workspace settings and project structure

**Permissions and Access Rights**

- Ensure file system permissions allow read/write access to project directories
- Verify network permissions for package managers (npm, Maven Central, PyPI)
- Check API keys and authentication tokens for external services
- Confirm access to private repositories or enterprise package registries

## Build and Deployment Verification

**Terminal Command Testing**

- Run build commands (`mvn clean compile`, `npm install`, `gradle build`) to verify the project compiles successfully
- Execute test suites to ensure existing functionality works as expected
- Package the application using standard commands to confirm deployment readiness
- Test run commands to verify the application starts and functions correctly

## Additional Critical Preparations

**Documentation and Context Review**

- Review project README files and technical documentation to understand architecture and coding standards
- Examine existing code patterns and conventions to help AI provide consistent suggestions
- Check for project-specific linting rules, formatting standards, and style guides
- Review recent commit history to understand current development focus and potential issues

**Dependency and Security Audit**

- Run dependency vulnerability scans (`npm audit`, `mvn dependency:check`) to identify security issues
- Update outdated packages where appropriate, but test thoroughly afterward
- Verify license compatibility for all dependencies, especially in commercial projects
- Check for deprecated libraries that might affect AI code generation quality

**Performance and Resource Monitoring**

- Monitor system resources (CPU, memory, disk space) as AI code editors can be resource-intensive
- Close unnecessary applications to free up system resources for optimal AI performance
- Check internet connectivity stability since many AI features require cloud connectivity
- Verify backup systems are in place before making significant code changes

**Team Collaboration Setup**

- Communicate with team members about AI tool usage policies and coding standards
- Ensure shared development databases or services are accessible and current
- Verify that AI-generated code will be compatible with team workflows and review processes
- Set up appropriate branching strategy for AI-assisted development work

**AI Tool Configuration**

- Configure AI code editor settings to match your project's programming language and framework
- Set up custom prompts or templates that align with your project's specific requirements
- Adjust AI suggestion sensitivity and filtering based on your experience level and project complexity
- Enable or disable specific AI features based on your security policies and project requirements

The importance of these preparations cannot be overstated. Proper setup ensures that AI code editors can provide accurate, contextually relevant suggestions while minimizing the risk of introducing bugs, security vulnerabilities, or code that doesn't align with your project's standards. A well-prepared environment allows you to maximize the benefits of AI assistance while maintaining code quality and project integrity.

## 9. AI Code Editors features comparison

| **Feature** | **GitHub Copilot** | **Cline** | **Cursor** | **Windsurf** | **Zed** |
| --- | --- | --- | --- | --- | --- |
| **Ask Mode** (Query-based assistance) | **Copilot Chat**: Context-aware chat integrated in VS Code, allows asking questions about code, explanations, or improvements. | **Chat Interface with @file**: Allows querying with file context, supports natural language tasks, and suggests fixes based on environment monitoring. | **Chat (⌘ + L)**: Context-aware chat with project-wide understanding, supports drag-and-drop folders and image context. | **Cascade Chat**: Context-aware chat with natural language queries, enhanced by Cascade Memories for session continuity. | **AI Chat Integration**: Supports querying with LLMs for code generation and analysis, unobtrusive until needed. |
| **Edit Mode** (Code modification) | **Edits Feature**: Multi-file edits via natural language prompts, with reviewable changes (can be slow, manual file selection advised). | **Plan and Act Modes**: Proposes and executes multi-file edits, runs commands, and modifies files with user approval. | **Edit Mode**: Replaces Composer Mode, supports multi-file refactoring and bulk updates via natural language. | **Cascade Multi-File Edits**: Autonomous multi-file edits with context awareness, sometimes overly aggressive. | **Multibuffer Editing**: Compose and edit code excerpts across files in one surface, with AI-driven transformations. |
| **Agent Mode** (Autonomous task handling) | **Agent Mode**: Runs terminal commands, manages files, and automates tasks with user-defined file sets. | **Agentic Features**: Autonomous agent runs commands, creates files, and verifies changes (e.g., running tests). Strong for large projects. | **Agent Mode**: Handles complex multi-step tasks, auto-imports symbols, and runs commands with project context. | **Cascade Agent**: Highly agentic, auto-fills context, runs commands, and manages multi-file tasks. Noted for speed and autonomy. | **Agentic AI Integration**: Executes commands and manages tasks, focused on collaboration and transparency. |
| **Editor in Chat** (Inline chat within editor) | **Inline Suggestions with Chat**: Inline code suggestions via Copilot Chat, accepts or cycles suggestions (Alt+] or Alt+[). | **Chat-Driven Editing**: Inline suggestions and edits via chat interface, with shared context between Plan and Act modes. | **Inline Editing with Chat**: Inline AI suggestions integrated with chat, applies changes directly from chat. | **Supercomplete with Chat**: Inline suggestions via Supercomplete, with diff box for smarter edits, tied to Cascade chat. | **Inline AI Editing**: Inline code suggestions with chat integration, designed for real-time collaboration. |
| **Add Chat Participant** (Collaboration) | **Copilot in Pull Requests**: Supports collaborative code reviews in GitHub pull requests, no direct in-editor participant chat. | **No Direct Equivalent**: Lacks explicit multi-user chat, but open-source nature allows team customization. | **Collaboration Features**: Advanced team collaboration tools, but no specific in-editor chat participant feature. | **No Direct Equivalent**: Focuses on individual workflows, no explicit multi-user chat in editor. | **Real-Time Collaboration**: Built-in chat and screen-sharing for team collaboration within the editor. |
| **Add Tools** (Extensibility) | **Copilot Agents**: Extends functionality with custom AI tools for documentation, data retrieval, etc. Supports VS Code extensions. | **Model Context Protocol**: Extensible via custom tools, supports OpenRouter, Anthropic, OpenAI, and local models. | **VS Code Extension Support**: Leverages VS Code extension marketplace, integrates tools like Supermaven. | **VS Code Extension Support**: Access to VS Code extension marketplace, integrates with tools like Builder.io. | **Extensibility via Tree-sitter/WASM**: Supports Language Server Protocol and custom AI integrations. |
| **Additional Notes** | - Pricing: $10/month (Pro), free tier with 12,000 completions.
- Strong IDE integration, weaker project-wide context. | - Pricing: Free, open-source, requires API keys for models.
- Excels in large projects, privacy-focused. | - Pricing: $20/month (Pro), free trial with 250 credits.
- Best for project-wide understanding, fast tab completion. | - Pricing: Free tier, $15/month (Pro).
- Highly agentic, privacy-first, clean UI. | - Pricing: Free, open-source.
- Focus on performance, collaboration, not a VS Code fork. |

[GitHub Copilot cheat sheet](https://docs.github.com/en/copilot/using-github-copilot/copilot-chat/github-copilot-chat-cheat-sheet?tool=vscode)

### Notes:

- **GitHub Copilot** is a VS Code extension, not a standalone IDE, making it highly compatible but less project-aware compared to Cursor and Windsurf.
- **Cline** shines in open-source flexibility and agentic capabilities, ideal for privacy-conscious teams but may require technical setup.
- **Cursor** and **Windsurf** are VS Code forks, offering robust AI-first experiences with strong multi-file editing and agentic features. Windsurf is noted for being more autonomous and faster in some cases.
- **Zed** stands out as a non-VS Code-based editor, built in Rust for performance, with strong collaboration features but less mature AI capabilities.

## 10. MCP servers work in AI code editors

MCP (Model Context Protocol) server is **a specialized server that enables AI models to interact with external data sources, tools, and APIs in a standardized and secure way**. It acts as an interface, translating requests from an AI model into commands that a specific tool or service understands. This allows AI applications to access and utilize information from various sources without complex coding or integration processes. 

![image.png](attachment:7be5bcda-9567-4a18-b574-c047b2fe1ff6:image.png)

- **Protocol Standardization** - MCP provides a standardized way for AI assistants to connect with external data sources and tools, eliminating the need for custom integrations for each service or tool
- **Server-Client Architecture** - MCP servers act as intermediaries between AI code editors and various development tools, databases, APIs, and services, with the AI assistant as the client making requests through the protocol
- **Tool and Resource Exposure** - MCP servers expose specific tools (executable functions) and resources (data sources) that AI assistants can discover and utilize, such as file systems, databases, version control systems, or build tools
- **Dynamic Capability Discovery** - AI code editors can query MCP servers to understand what capabilities are available, allowing for flexible integration without hardcoded knowledge of each tool
- **Contextual Data Access** - MCP servers provide AI assistants with real-time access to project-specific context like file contents, git history, environment variables, and configuration files
- **Secure Sandboxed Execution** - MCP servers can execute commands and scripts in controlled environments, allowing AI to perform actions like running tests, building code, or deploying applications safely
- **Multi-Server Support** - Code editors can connect to multiple MCP servers simultaneously, aggregating capabilities from different tools and services into a unified AI assistant experience
- **Language-Agnostic Integration** - MCP works across different programming languages and development environments, providing consistent AI assistance regardless of the tech stack
- **Local and Remote Server Support** - MCP servers can run locally on the developer's machine or remotely as cloud services, offering flexibility in deployment and resource management
- **Real-time Communication** - The protocol supports bidirectional communication, allowing servers to push updates and notifications to AI assistants about changes in the development environment
- **Permission and Access Control** - MCP includes mechanisms for managing what actions AI assistants can perform through connected servers, ensuring security and preventing unauthorized operations.

## Day 2: **MCP Server using Spring AI - LAB**

![Screenshot 2025-05-29 175157.png](attachment:9766b27d-4de7-41d5-ab15-efb501f9536c:Screenshot_2025-05-29_175157.png)

## Day 3: **MCP Server using Spring AI - LAB**
